{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beat Generation - DevFest Nantes 2021 - IArt\n",
    "\n",
    " \n",
    "<br>  \n",
    "Brique n¬∞3 de la conf√©rence **IArt ou comment apprendre √† une machine √† tagger et √† composer**\n",
    " \n",
    "<br>  \n",
    "\n",
    "<img src=\"images/image1.jpg\" alt=\"Beat Generation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectifs\n",
    " \n",
    "<br>  \n",
    "- Introduction √† la g√©n√©ration d'un signal audio\n",
    "<br>  \n",
    "<br>  \n",
    "- Cr√©er un beat pour notre tube üé∏ü§òüéºüéµ‚ô¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapes\n",
    "\n",
    "<br>  \n",
    "1. On va lire l'ensemble des fichiers Midi √† disposition\n",
    "<br>  \n",
    "    - Dans un premier temps, on va analyser les fichiers pour d√©finir un interval de temps fix entre deux notes.\n",
    "    - Ensuite, on va lire tous les fichiers et concat√©ner les notes dans une seule liste (avec un √©cart de temps entre deux fichiers).  \n",
    "<br>  \n",
    "2. Cr√©ation d'une s√©quence de \"classes\" √† pr√©dire\n",
    "<br>  \n",
    "    - On va cr√©er une \"classe\" par couple note/v√©locit√©\n",
    "    - On va ensuite \"compl√©ter\" les intervals de temps par des \"blancs\" pour avoir une note par interval de temps.  \n",
    "<br>  \n",
    "3. Gestion des \"blancs\"\n",
    "<br>  \n",
    "    - Apr√®s quelques exp√©riences, on s'est rendu compte qu'il fallait mieux regrouper les \"blancs\" par groupes  \n",
    "        - En effet, on peut avoir plus de 20 \"blancs\" √† suivre, ce qui va compl√®tement fausser notre mod√®le.  \n",
    "        - Dans les fait, on peut quand m√™me obtenir des bons r√©sultats, mais √ßa n√©cessite un apprentissage tr√®s long sur un mod√®le complexe.  \n",
    "\n",
    "    - On analyse donc la s√©quence de notes (classes) et on va regrouper les \"blancs\" dans des nouvelles \"m√©ta\"-classes de \"blancs\"  \n",
    "<br>  \n",
    "4. Modelisation\n",
    "<br>  \n",
    "    - On d√©finit la cible de notre mod√®le -> pr√©dire la note suivante d'une s√©quence.\n",
    "    - On cr√©√© un mod√®le r√©current qui prend en entr√©e une s√©quence de note.  \n",
    "<br>  \n",
    "5. Entrainement\n",
    "<br>  \n",
    "    - On entraine le mod√®le sur l'int√©gralit√© de nos donn√©es.\n",
    "        - Pas oblig√© d'avoir un jeu de validation, on veut volontairement overfitter le mod√®le pour apprendre au mieux le \"genre\" des beats en entr√©e.  \n",
    "<br>  \n",
    "6. Pr√©dictions\n",
    "<br>  \n",
    "    - Enfin, on va vouloir utiliser notre mod√®le pour cr√©er un nouveau son !  \n",
    "    - Id√©e :\n",
    "      - Fournir une s√©quence en entr√©e (al√©atoire, une seule note, ou encore une s√©quence choisie manuellement, ...)\n",
    "      - Pr√©dire la prochaine note\n",
    "      - Recr√©er une s√©quence avec la nouvelle note (moins la premi√®re note de la s√©quence pr√©c√©dente)\n",
    "      - Continuer jusqu'√† avoir un certain nombre de notes  \n",
    "    - La fonction de g√©n√©ration inclut une s√©lection \"al√©atoire\" selon la distribution des pr√©dictions obtenues par le mod√®le, pour apporter un peu de vari√©t√©.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divers\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, Javascript, clear_output\n",
    "\n",
    "# Musique\n",
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack, second2tick, MetaMessage\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (ELU, LSTM, BatchNormalization, Bidirectional, Embedding, Softmax,\n",
    "                                     Dense, Dropout, Input, LeakyReLU, ReLU, GRU, SpatialDropout1D)\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Center figures\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions utilitaires\n",
    "\n",
    "<br>  \n",
    "On commence par d√©finir certaines fonctions utilitaires :\n",
    "\n",
    "- **hide_toggle** : permet de \"masquer\" certaines cellules de ce notebook, ce qui permet d'apporter un peu plus de clart√© ;)   \n",
    "\n",
    "- **load_midi_file** : Fonction pour lire un fichier midi   \n",
    "\n",
    "- **play_midi_messages** : Fonction pour lire une suite de notes Midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_766701176154087293() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_766701176154087293()\" id=\"code_toggle_766701176154087293\">Toggle show/hide --- fonction hide_toggle</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hide_toggle(for_next=False, text_display='Toggle show/hide'):\n",
    "    '''Function to hide a notebook cell'''\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = f\"\"\"\n",
    "        <script>\n",
    "            function {js_f_name}() {{\n",
    "                {target_cell}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{js_f_name}()\" id=\"{js_f_name}\">{text_display}</a>\n",
    "    \"\"\"\n",
    "    \n",
    "    js = f'''\n",
    "            var output_area = this;\n",
    "            var cell_element = output_area.element.parents('.cell');\n",
    "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
    "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
    "            $(current_cell.element[0]).find('div.input').toggle();\n",
    "            Jupyter.notebook.select(cell_idx +  1);\n",
    "            Jupyter.notebook.focus_cell();\n",
    "         '''\n",
    "\n",
    "    display(HTML(html))\n",
    "    display(Javascript(js))\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction hide_toggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6331198851935951122() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6331198851935951122()\" id=\"code_toggle_6331198851935951122\">Toggle show/hide --- fonction load_midi_file</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_midi_file(file_path: str, min_time_gap: float = 0.):\n",
    "    '''Fonction pour lire un fichier midi\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): chemin du fichier √† lire\n",
    "        min_time_gap (float): √©cart minimum entre deux notes\n",
    "            Permet de ne pas avoir deux notes en m√™me temps √† pr√©dire pour notre algorithme\n",
    "            Default 0. -> pas de d√©calage\n",
    "            G√©n√©ralement on veut avoir min_time_gap assez faible pour ne pas avoir de diff√©rence sur le rendu\n",
    "    Returns:\n",
    "        list : liste des notes du fichier Midi\n",
    "    '''\n",
    "    messages = []\n",
    "    for i, msg in enumerate(MidiFile(file_path)):\n",
    "        if not msg.is_meta:\n",
    "            # Si deux notes en m√™me temps, on d√©cale la deuxi√®me pour la mettre juste apr√®s la premi√®re\n",
    "            # i.e. temps = temps minimum entre deux notes\n",
    "            if msg.time < min_time_gap:\n",
    "                msg.time = min_time_gap\n",
    "            messages.append(msg)\n",
    "    return messages\n",
    "\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction load_midi_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_17249411935183184647() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_17249411935183184647()\" id=\"code_toggle_17249411935183184647\">Toggle show/hide --- fonction play_midi_messages</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def play_midi_messages(messages):\n",
    "    '''Fonction pour lire une suite de notes Midi\n",
    "    \n",
    "    Args:\n",
    "        messages (list): notes √† jouer\n",
    "    '''\n",
    "    outport = mido.open_output()\n",
    "    for i, msg in enumerate(messages):\n",
    "        time.sleep(msg.time)\n",
    "        outport.send(msg)\n",
    "    outport.close()\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction play_midi_messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6675090513941435351() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6675090513941435351()\" id=\"code_toggle_6675090513941435351\">Toggle show/hide --- fonction save_midi_messages</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_midi_messages(midi_messages: list, new_file_path: str):\n",
    "    '''Fonction pour sauvegarder une liste de messages MIDI en un fichier midi\n",
    "    \n",
    "    De nombreux param√®tres sont fix√©s apr√®s analyse de nos donn√©es\n",
    "    \n",
    "    Args:\n",
    "        midi_messages (list): liste de messages √† sauvegarder\n",
    "        new_file_path (str): chemin du fichier √† cr√©er\n",
    "    '''\n",
    "    # Init midi file\n",
    "    mid = MidiFile()\n",
    "    \n",
    "    # On ajoute des infos sp√©cifiques √† nos donn√©es    \n",
    "    mid.type = 1 # c.f. `MidiFile(\"original_beats/078 Hip Hop Beat 1A.mid\").type`\n",
    "    # c.f. `MidiFile(\"original_beats/078 Hip Hop Beat 1A.mid\").tracks[0]`\n",
    "    mid.tracks.append(\n",
    "        MidiTrack(\n",
    "            [\n",
    "                MetaMessage('track_name', name='AI generated song', time=0),\n",
    "                MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0),\n",
    "                MetaMessage('key_signature', key='C', time=0),\n",
    "                MetaMessage('set_tempo', tempo=769231, time=0),\n",
    "                MetaMessage('end_of_track', time=0),\n",
    "            ])\n",
    "    )\n",
    "\n",
    "    # Notre track\n",
    "    track = MidiTrack()\n",
    "    for msg in midi_messages:\n",
    "        # Time en ticks pour sauvegarde en midi\n",
    "        # ticks_per_beat: MidiFile(\"original_beats/078 Hip Hop Beat 1A.mid\").ticks_per_beat\n",
    "        # tempo: MidiFile(\"original_beats/078 Hip Hop Beat 1A.mid\").tracks[0][3].tempo\n",
    "        # On va cr√©er un nouveau message, car on ne veut pas modifier l'original\n",
    "        msg_tick_time = round(second2tick(msg.time, 240, 769231)) * 2 # x 2 donne le bon timing. TODO : se renseigner sur la librairie mido\n",
    "        final_msg = Message('note_on', channel=9, note=msg.note, velocity=msg.velocity, time=msg_tick_time)\n",
    "        track.append(final_msg)\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    # Save\n",
    "    mid.save(new_file_path)\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction save_midi_messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lecture des fichiers Midi\n",
    "\n",
    "<br>\n",
    "\n",
    "- On va cr√©er une suite de notes qui sera la concat√©nation de tous les fichiers √† disposition  \n",
    "- On ajoute un petit √©cart de temps entre deux fichiers  \n",
    "- Au final on voudra une suite de notes avec un interval de temps fix entre deux notes  \n",
    "  - On d√©finit la valeur de cet interval de temps √† la suite d'une analyse sur les fichiers √† disposition\n",
    "  - Dans la suite, on va remplir les trous avec des notes \"blancs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'√©cart minimum entre deux notes est √©gal √† 0.00321\n"
     ]
    }
   ],
   "source": [
    "# On analyse les donn√©es\n",
    "list_times = []\n",
    "for file in glob.glob(\"original_beats/*.mid\"): # On parcours l'ensemble des fichiers midi √† disposition\n",
    "    file_midi_messages = load_midi_file(file)\n",
    "    for message in file_midi_messages:\n",
    "        if message.time != 0:\n",
    "            list_times.append(message.time)\n",
    "min_interval = min(list_times)\n",
    "print(f\"L'√©cart minimum entre deux notes est √©gal √† {round(min_interval, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On d√©finit certains param√®tres\n",
    "time_split_files = 0.1 # On ajoute un temps entre deux fichiers (pour ne pas les enchainer trop vite !)\n",
    "interval_time = min_interval * 4 # On augmente l'√©cart minimum entre deux notes pour diminuer le nombre de \"blancs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de l'ensemble des notes\n",
    "midi_messages = []\n",
    "for file in glob.glob(\"original_beats/*.mid\"):\n",
    "    file_midi_messages = load_midi_file(file)\n",
    "    for i, msg in enumerate(file_midi_messages):\n",
    "        # On ajoute un temps entre deux fichiers\n",
    "        if i == 0:\n",
    "            msg.time = 0.1\n",
    "        # Si deux notes se suivent √† moins de interval_time, on d√©cale la deuxi√®me pour la mettre juste apr√®s la premi√®re\n",
    "        elif msg.time < interval_time:\n",
    "            msg.time = interval_time\n",
    "        midi_messages.append(msg)\n",
    "midi_messages[0].time = 0 # On set le premier temps √† 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On joue les premi√®re notes pour v√©rifier la coh√©rence du signal\n",
    "play_midi_messages(midi_messages[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cr√©ation d'une s√©quence de \"classes\" √† pr√©dire\n",
    "\n",
    "<br>\n",
    "\n",
    "- On va cr√©er une \"classe\" par couple note/v√©locit√©\n",
    "- On va ensuite \"compl√©ter\" les intervals de temps par des \"blancs\" pour avoir une note par interval de temps.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a 7 notes diff√©rentes dans notre jeu de donn√©es\n",
      "On a 101 couples notes/v√©locit√© diff√©rents dans notre jeu de donn√©es\n"
     ]
    }
   ],
   "source": [
    "# Analyse des notes de notre dataset\n",
    "print(f\"On a {len(set([msg.note for msg in midi_messages]))} notes diff√©rentes dans notre jeu de donn√©es\")\n",
    "print(f\"On a {len(set([(msg.note, msg.velocity) for msg in midi_messages]))} couples notes/v√©locit√© diff√©rents dans notre jeu de donn√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on avait plus de couples diff√©rents, on pourrait seuiller les v√©locit√©s pour r√©duire ce nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['36_116', '36_110', '37_100', '42_64', '38_103']\n"
     ]
    }
   ],
   "source": [
    "# On d√©finit une classe par couple note/v√©locit√©\n",
    "available_couples = sorted(list(set([f'{msg.note}_{msg.velocity}' for msg in midi_messages])))\n",
    "# On cr√©√© un \"tokenizer\" : note -> token\n",
    "notes_to_tokens = {note: i for i, note in enumerate(available_couples)}\n",
    "# On affiche 5 √©l√©ments pour exemple\n",
    "print(random.sample(available_couples, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rajoute une note \"blanc\"\n",
    "notes_to_tokens['blanc'] = len(notes_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On d√©finit le dictionnaire inverse\n",
    "classes_to_notes = {value: key for key, value in notes_to_tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['42_69', '36_114', 'blanc', 'blanc', 'blanc', 'blanc', 'blanc', 'blanc', 'blanc', '42_0']\n"
     ]
    }
   ],
   "source": [
    "# On cr√©√© une s√©quence de notes (classes) en compl√©tant les intervals par des \"blancs\"\n",
    "notes_seq = []\n",
    "for msg in midi_messages:\n",
    "    cl = f'{msg.note}_{msg.velocity}'\n",
    "    nb_blanc_steps = round(msg.time/interval_time) - 1\n",
    "    if nb_blanc_steps > 0:\n",
    "        notes_seq += ['blanc'] * nb_blanc_steps\n",
    "    notes_seq.append(cl)\n",
    "\n",
    "# On affiche le d√©but\n",
    "print(notes_seq[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gestion des \"blancs\"\n",
    "\n",
    "<br>\n",
    "\n",
    "- Apr√®s quelques exp√©riences, on s'est rendu compte qu'il fallait mieux regrouper les \"blancs\" par groupes  \n",
    "    - En effet, on peut avoir plus de 20 \"blancs\" √† suivre, ce qui va risque de fausser notre mod√®le.  \n",
    "    - Dans les fait, on peut quand m√™me obtenir des bons r√©sultats, mais √ßa n√©cessite un apprentissage tr√®s long sur un mod√®le complexe.  \n",
    "- On analyse donc la s√©quence de notes (classes) et on va regrouper les \"blancs\" dans des nouvelles \"m√©ta\"-classes de \"blancs\" \n",
    "<br>   \n",
    "<br>   \n",
    "\n",
    "On d√©finit quelques fonctions pour clarifier le notebook :\n",
    "\n",
    "- **cnt_blancs** : Fonction pour compter les \"blancs\" dans une s√©quence  \n",
    "- **regroup_blancs** : Fonction pour regrouper les \"blancs\" dans des \"m√©ta\"-classes de blancs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6333020631357042215() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6333020631357042215()\" id=\"code_toggle_6333020631357042215\">Toggle show/hide --- fonction cnt_blancs</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cnt_blancs(seq: list):\n",
    "    '''Fonction pour compter les \"blancs\" dans une s√©quence\n",
    "    \n",
    "    Args:\n",
    "        seq (list): s√©quence √† analyser\n",
    "    '''\n",
    "    # On commence par regarder les classes de 'blancs' pr√©sentes dans la s√©quence\n",
    "    list_classes_blancs = list(set([note for note in seq if note.startswith('blanc')]))\n",
    "    \n",
    "    # Analyse des occurrences\n",
    "    for cl_blanc in list_classes_blancs:\n",
    "        print(f\"On a {round(seq.count(cl_blanc) / len(seq) * 100, 2)} % de note '{cl_blanc}' dans notre s√©quence de notes.\")\n",
    "    print(f\"On a {round(len([_ for _ in seq if not _.startswith('blanc')]) / len(seq) * 100, 2)} % de 'vraies' notes dans notre s√©quence de notes.\")\n",
    "        \n",
    "    # Analyse des suites\n",
    "    for cl_blanc in list_classes_blancs:\n",
    "        print(f\"\\nAnalyse de la classe '{cl_blanc}':\\n\")\n",
    "        # On r√©cup√®re le compte des suite\n",
    "        nb_blanc = 0\n",
    "        blancs_cnt = {}\n",
    "        for note in seq:\n",
    "            if note == cl_blanc:\n",
    "                nb_blanc += 1\n",
    "            elif nb_blanc != 0:\n",
    "                blancs_cnt[nb_blanc] = blancs_cnt.get(nb_blanc, 0) + 1\n",
    "                nb_blanc = 0\n",
    "        # Affichage\n",
    "        for key in sorted(list(blancs_cnt.keys())):\n",
    "            print(f\"    Il y a {blancs_cnt[key]} suites de {key} '{cl_blanc}'\")\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction cnt_blancs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_11101686095540038613() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_11101686095540038613()\" id=\"code_toggle_11101686095540038613\">Toggle show/hide --- fonction regroup_blancs</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def regroup_blancs(notes_seq: list, groupes_dict: dict):\n",
    "    '''Fonction pour regrouper les \"blancs\" dans des \"m√©ta\"-classes de blancs\n",
    "    \n",
    "    Args:\n",
    "        seq (list): s√©quence √† analyser\n",
    "        groupes_dict (dict): dictionnaire avec les regroupements √† faire\n",
    "            cl√© : nb d'occurrences √† suivre\n",
    "            valeur : nouvelle classe √† associer\n",
    "    Returns:\n",
    "        list: nouvelle s√©quence mise √† jour\n",
    "    '''\n",
    "    min_notes = min(groupes_dict.keys()) # nombre minimal de blancs pour regroupement, d'apr√®s nos choix\n",
    "    \n",
    "    # On va parcourir la s√©quence jusqu'√† trouver une suite de blancs √©ligible\n",
    "    # A chaque suite trouv√©e, on met √† jour la s√©quence de notes\n",
    "    # Il faut donc recommencer le parcours avec cette nouvelle s√©quence (d'o√π le while)\n",
    "\n",
    "    work_to_do = True # Tant qu'il y a des suites de blancs √©ligibles\n",
    "    while work_to_do:\n",
    "        started = False # Indique si on a d√©marr√© l'√©tude d'une suite de 'blancs'\n",
    "        breaked = False # Indique si la boucle for √† √©t√© break\n",
    "                        # i.e. on a trouv√© une s√©quence de blanc, on reparcours le s√©quence depuis le d√©but\n",
    "        cnt = 0 # Nb de blancs identifi√©s\n",
    "        start_index = 0 # Index du d√©but de la suite de blancs √† l'√©tude\n",
    "\n",
    "        # On parcours l'int√©gralit√© de la s√©quence de notes\n",
    "        for i, note in enumerate(notes_seq):\n",
    "\n",
    "            # Init cnt\n",
    "            if note == 'blanc' and started == False:\n",
    "                start_index = i\n",
    "                started = True\n",
    "                cnt = 1\n",
    "\n",
    "            # Another blanc\n",
    "            elif started == True and note == 'blanc':\n",
    "                cnt += 1\n",
    "\n",
    "            # Not a blanc\n",
    "            elif started == True and note != 'blanc':\n",
    "                # Pas assez de notes pour regrouper\n",
    "                if cnt < min_notes:\n",
    "                    started=False\n",
    "                    cnt = 0\n",
    "                # Assez de notes, on regroupe\n",
    "                else:\n",
    "                    end_index = i\n",
    "                    notes_seq = notes_seq[:start_index] + [groupes_dict[cnt]] + notes_seq[end_index:]\n",
    "                    # On indique qu'il faut continuer\n",
    "                    breaked = True\n",
    "                    # On break la boucle\n",
    "                    break        \n",
    "\n",
    "        if not breaked:\n",
    "            # Si on n'a pas trouv√© de suite √©ligible dans l'int√©gralit√© de la s√©quence, on quitte la boucle\n",
    "            work_to_do = False\n",
    "    \n",
    "    # Return nouvelle s√©quence\n",
    "    return notes_seq\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction regroup_blancs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a 88.23 % de note 'blanc' dans notre s√©quence de notes.\n",
      "On a 11.77 % de 'vraies' notes dans notre s√©quence de notes.\n",
      "\n",
      "Analyse de la classe 'blanc':\n",
      "\n",
      "    Il y a 3 suites de 1 'blanc'\n",
      "    Il y a 36 suites de 5 'blanc'\n",
      "    Il y a 264 suites de 6 'blanc'\n",
      "    Il y a 479 suites de 7 'blanc'\n",
      "    Il y a 9 suites de 8 'blanc'\n",
      "    Il y a 6 suites de 20 'blanc'\n",
      "    Il y a 357 suites de 21 'blanc'\n",
      "    Il y a 45 suites de 22 'blanc'\n",
      "    Il y a 24 suites de 23 'blanc'\n"
     ]
    }
   ],
   "source": [
    "# Analyse des 'blancs'\n",
    "cnt_blancs(notes_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a trop de 'blancs', on d√©cide donc de faire des regroupements\n",
    "- On regroupe 5 & 6 ensemble\n",
    "- On regroupe 7 & 8 ensemble\n",
    "- On regroupe 20, 21, 22 & 23 ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajout les nouvelles classes de \"blancs\"\n",
    "new_notes = ['blanc_6', 'blanc_7', 'blanc_21']\n",
    "for note in new_notes:\n",
    "    notes_to_tokens[note] = len(notes_to_tokens)\n",
    "    classes_to_notes[len(classes_to_notes)] = note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cr√©√© un dictionnaire de regroupement de 'blancs'\n",
    "cnt_to_notes_dict = {\n",
    "    5: 'blanc_6', # On regroupe 5 & 6 ensemble\n",
    "    6: 'blanc_6', # On regroupe 5 & 6 ensemble\n",
    "    7: 'blanc_7', # On regroupe 7 & 8 ensemble\n",
    "    8: 'blanc_7', # On regroupe 7 & 8 ensemble\n",
    "    20: 'blanc_21', # On regroupe 20, 21, 22 & 23 ensemble\n",
    "    21: 'blanc_21', # On regroupe 20, 21, 22 & 23 ensemble\n",
    "    22: 'blanc_21', # On regroupe 20, 21, 22 & 23 ensemble\n",
    "    23: 'blanc_21', # On regroupe 20, 21, 22 & 23 ensemble\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On transforme notre s√©quence pour y int√©grer les regroupements de blancs\n",
    "final_notes_seq = regroup_blancs(notes_seq, cnt_to_notes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a 15.56 % de note 'blanc_7' dans notre s√©quence de notes.\n",
      "On a 13.77 % de note 'blanc_21' dans notre s√©quence de notes.\n",
      "On a 0.1 % de note 'blanc' dans notre s√©quence de notes.\n",
      "On a 9.56 % de note 'blanc_6' dans notre s√©quence de notes.\n",
      "On a 61.01 % de 'vraies' notes dans notre s√©quence de notes.\n",
      "\n",
      "Analyse de la classe 'blanc_7':\n",
      "\n",
      "    Il y a 488 suites de 1 'blanc_7'\n",
      "\n",
      "Analyse de la classe 'blanc_21':\n",
      "\n",
      "    Il y a 432 suites de 1 'blanc_21'\n",
      "\n",
      "Analyse de la classe 'blanc':\n",
      "\n",
      "    Il y a 3 suites de 1 'blanc'\n",
      "\n",
      "Analyse de la classe 'blanc_6':\n",
      "\n",
      "    Il y a 300 suites de 1 'blanc_6'\n"
     ]
    }
   ],
   "source": [
    "# On analyse notre nouvelle s√©quence\n",
    "cnt_blancs(final_notes_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois-ci on a plus de 60% de 'vraies' notes, c'est mieux !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelisation\n",
    "\n",
    "<br>\n",
    "\n",
    "- On d√©finit la cible de notre mod√®le -> pr√©dire la note suivante d'une s√©quence.\n",
    "- On cr√©√© un mod√®le r√©current qui prend en entr√©e une s√©quence de note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres\n",
    "sequence_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cr√©e les entr√©es/sorties de notre mod√®le\n",
    "# Il s'agit de l'ensemble des s√©quences de longueur 'sequence_length', et de la prochaine note √† pr√©dire\n",
    "network_input = []\n",
    "network_output = []\n",
    "for i in range(0, len(final_notes_seq) - sequence_length, 1):\n",
    "    sequence_in = final_notes_seq[i:i + sequence_length]\n",
    "    sequence_out = final_notes_seq[i + sequence_length]\n",
    "    network_input.append([notes_to_tokens[note] for note in sequence_in])\n",
    "    network_output.append(notes_to_tokens[sequence_out])\n",
    "\n",
    "# On reshape nos donn√©es pour √™tre compatible avec un r√©seau de neurones r√©current\n",
    "network_input = np.reshape(network_input, (len(network_input), sequence_length))\n",
    "network_output = to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 200, 10)           1060      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               273408    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "elu (ELU)                    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 105)               26985     \n",
      "=================================================================\n",
      "Total params: 369,293\n",
      "Trainable params: 368,269\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# D√©finition de notre mod√®le r√©current\n",
    "num_classes = network_output.shape[1]\n",
    "embedding_size = 10 # Param√®trable\n",
    "\n",
    "# Set model\n",
    "model_in = Input(shape=(sequence_length,))\n",
    "# Embedding : On ajoute une classe pour permettre des notes OOV\n",
    "#             embeddings_initializer = zeros ? (pour gestion OOV)\n",
    "x = Embedding(num_classes + 1, embedding_size, trainable=True)(model_in)\n",
    "# x = LSTM(512, return_sequences=True)(x)  --> On peut rajouter une couche LSTM, mais long et pas tr√®s utile\n",
    "x = LSTM(256, return_sequences=False)(x)\n",
    "x = BatchNormalization(momentum=0.9)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation=None, kernel_initializer=\"he_uniform\")(x)\n",
    "x = BatchNormalization(momentum=0.9)(x)\n",
    "x = ELU(alpha=1.0)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Last layer - On fait de la classification mono-label / multi-classes : activation softmax\n",
    "activation = 'softmax'\n",
    "out = Dense(num_classes, activation=activation, kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=model_in, outputs=[out])\n",
    "lr = 0.01\n",
    "optimizer = Adam(lr=lr)\n",
    "# Loss / Metrics - On fait de la classification mono-label / multi-classes : categorical accuracy\n",
    "metrics = ['categorical_accuracy']\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Entrainement\n",
    "\n",
    "<br>\n",
    "\n",
    "- On entraine le mod√®le sur l'int√©gralit√© de nos donn√©es.\n",
    "    - Pas oblig√© d'avoir un jeu de validation, on veut volontairement overfitter le mod√®le pour apprendre au mieux le \"genre\" des beats en entr√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'ensemble des donn√©es seront sauvegard√©es dans le r√©pertoire C:\\Users\\Alexandre\\Dev\\Valeuriad\\devfest-2021\\03_beat-generation\\experimentation_2021_10_17-17_02_02\n"
     ]
    }
   ],
   "source": [
    "# On va cr√©er un dossier o√π sauvegarder tous nos mod√®les & predictions\n",
    "subfolder_name = datetime.now().strftime(f\"experimentation_%Y_%m_%d-%H_%M_%S\")\n",
    "os.makedirs(subfolder_name)\n",
    "subfolder_path = os.path.abspath(subfolder_name)\n",
    "print(f\"L'ensemble des donn√©es seront sauvegard√©es dans le r√©pertoire {subfolder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 2.5705 - categorical_accuracy: 0.43 - 1s 30ms/step - loss: 2.5705 - categorical_accuracy: 0.4317\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.5345 - categorical_accuracy: 0.5918\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.2435 - categorical_accuracy: 0.6544\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0885 - categorical_accuracy: 0.6816\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9572 - categorical_accuracy: 0.7143\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8427 - categorical_accuracy: 0.73 - 1s 28ms/step - loss: 0.8427 - categorical_accuracy: 0.7365\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.7816 - categorical_accuracy: 0.7579 0s - loss: 0.7775 - categorica\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.7121 - categorical_accuracy: 0.7818\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.6631 - categorical_accuracy: 0.7981\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.6488 - categorical_accuracy: 0.7971\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.6084 - categorical_accuracy: 0.8124\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.5516 - categorical_accuracy: 0.8226\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.4809 - categorical_accuracy: 0.8430 0s - loss: 0.4809 - categorical_accuracy: 0.84\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.4458 - categorical_accuracy: 0.8519\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.4328 - categorical_accuracy: 0.8546\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.4140 - categorical_accuracy: 0.8601\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.4004 - categorical_accuracy: 0.8638\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.3657 - categorical_accuracy: 0.8744\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.3429 - categorical_accuracy: 0.8829\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.3188 - categorical_accuracy: 0.8924\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.3469 - categorical_accuracy: 0.8846\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3120 - categorical_accuracy: 0.8941\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2715 - categorical_accuracy: 0.9053\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2693 - categorical_accuracy: 0.9043\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2391 - categorical_accuracy: 0.9159\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2643 - categorical_accuracy: 0.9091\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2872 - categorical_accuracy: 0.8975\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2641 - categorical_accuracy: 0.9094\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2302 - categorical_accuracy: 0.9186\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2336 - categorical_accuracy: 0.9149\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2135 - categorical_accuracy: 0.9248\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2102 - categorical_accuracy: 0.9305 0s - loss: 0.1372 - categorical_ac - ETA: 0s - loss: 0.2056 - categorical_accuracy\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2023 - categorical_accuracy: 0.9271\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1851 - categorical_accuracy: 0.9350\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1687 - categorical_accuracy: 0.9418\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1271 - categorical_accuracy: 0.9551\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1404 - categorical_accuracy: 0.9520\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1333 - categorical_accuracy: 0.9561\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1201 - categorical_accuracy: 0.9551\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1453 - categorical_accuracy: 0.9510\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1280 - categorical_accuracy: 0.9571\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1129 - categorical_accuracy: 0.9598\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1314 - categorical_accuracy: 0.9595\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1369 - categorical_accuracy: 0.9489\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1441 - categorical_accuracy: 0.9523\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1905 - categorical_accuracy: 0.9333\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1538 - categorical_accuracy: 0.9493 0s - loss: 0.1386 - catego\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1667 - categorical_accuracy: 0.9476\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1579 - categorical_accuracy: 0.9472\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1525 - categorical_accuracy: 0.9489\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1276 - categorical_accuracy: 0.9554\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1048 - categorical_accuracy: 0.9615\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0865 - categorical_accuracy: 0.9707\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0733 - categorical_accuracy: 0.9755\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0769 - categorical_accuracy: 0.9734\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0802 - categorical_accuracy: 0.9728\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0680 - categorical_accuracy: 0.9751\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0808 - categorical_accuracy: 0.9768\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1265 - categorical_accuracy: 0.9581\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0978 - categorical_accuracy: 0.9697\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0947 - categorical_accuracy: 0.9700\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0999 - categorical_accuracy: 0.9694\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0752 - categorical_accuracy: 0.9755\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0639 - categorical_accuracy: 0.9789\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0532 - categorical_accuracy: 0.9864\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0687 - categorical_accuracy: 0.9803\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0542 - categorical_accuracy: 0.9833\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0696 - categorical_accuracy: 0.9789\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0902 - categorical_accuracy: 0.9734\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0921 - categorical_accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1106 - categorical_accuracy: 0.9653 0s - loss: 0.0707 - categorica\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1127 - categorical_accuracy: 0.9646 0s - loss: 0.1112 - categorica\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1034 - categorical_accuracy: 0.9683\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0906 - categorical_accuracy: 0.9748\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0872 - categorical_accuracy: 0.9751\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0682 - categorical_accuracy: 0.9782 0s - loss: 0.0706 - categori\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0696 - categorical_accuracy: 0.9792 0s - loss: 0.0605 - categori\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0448 - categorical_accuracy: 0.9847\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0613 - categorical_accuracy: 0.9840\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0476 - categorical_accuracy: 0.9857\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0736 - categorical_accuracy: 0.9758\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0632 - categorical_accuracy: 0.9799\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0619 - categorical_accuracy: 0.9823 0s - loss: 0.1006 - catego\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0480 - categorical_accuracy: 0.9826\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0665 - categorical_accuracy: 0.9779\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0535 - categorical_accuracy: 0.9826\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0367 - categorical_accuracy: 0.9867 0s - loss: 0.0199 - categori\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0551 - categorical_accuracy: 0.9809\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0480 - categorical_accuracy: 0.9843\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0546 - categorical_accuracy: 0.9823\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0404 - categorical_accuracy: 0.9867\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0349 - categorical_accuracy: 0.9898 0s - loss: 0.0400 - categorical_accuracy\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0267 - categorical_accuracy: 0.9894 0s - loss: 0.0296 - categorical_accuracy\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0528 - categorical_accuracy: 0.9860\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0490 - categorical_accuracy: 0.9843\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0618 - categorical_accuracy: 0.9809\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0520 - categorical_accuracy: 0.9837\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0543 - categorical_accuracy: 0.9809\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0804 - categorical_accuracy: 0.9792\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0984 - categorical_accuracy: 0.9724\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0956 - categorical_accuracy: 0.9741 0s - loss: 0.0283 - catego\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0815 - categorical_accuracy: 0.9755\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0671 - categorical_accuracy: 0.9779 0s - loss: 0.0548 - categorical_ac\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1370 - categorical_accuracy: 0.9636 0s - loss: 0.1160 - categori\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1267 - categorical_accuracy: 0.9639\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0810 - categorical_accuracy: 0.9789\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0655 - categorical_accuracy: 0.9782\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0455 - categorical_accuracy: 0.9826\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0556 - categorical_accuracy: 0.9826\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0497 - categorical_accuracy: 0.9850\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0427 - categorical_accuracy: 0.9854\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0370 - categorical_accuracy: 0.9908\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0472 - categorical_accuracy: 0.9850\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0509 - categorical_accuracy: 0.9857\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0481 - categorical_accuracy: 0.9874 0s - loss: 0.0520 - catego\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0449 - categorical_accuracy: 0.9881 0s - loss: 0.0364 - categori\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0352 - categorical_accuracy: 0.9877\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0428 - categorical_accuracy: 0.9857 0s - loss: 0.0347 - categorical_accuracy: 0. - ETA: 0s - loss: 0.0332 - categorica\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0657 - categorical_accuracy: 0.9843 0s - loss: 0.0227 - categori\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0544 - categorical_accuracy: 0.9833\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0557 - categorical_accuracy: 0.9857\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0372 - categorical_accuracy: 0.9894 0s - loss: 0.0316 - categori\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0335 - categorical_accuracy: 0.9864\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0281 - categorical_accuracy: 0.9894\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0323 - categorical_accuracy: 0.9911\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0373 - categorical_accuracy: 0.9891 0s - loss: 0.0368 - categorical_accuracy: 0.\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0390 - categorical_accuracy: 0.9908\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0366 - categorical_accuracy: 0.9911\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0485 - categorical_accuracy: 0.9898\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0390 - categorical_accuracy: 0.9891\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0384 - categorical_accuracy: 0.9901\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0317 - categorical_accuracy: 0.9918 0s - loss: 0.0058 - catego\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0631 - categorical_accuracy: 0.9843 0s - loss: 0.0650 - categori\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0674 - categorical_accuracy: 0.9813\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0864 - categorical_accuracy: 0.9772 0s - loss: 0.0720 - categorica\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0797 - categorical_accuracy: 0.9775\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0846 - categorical_accuracy: 0.9724\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0850 - categorical_accuracy: 0.9748\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0699 - categorical_accuracy: 0.9782\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0701 - categorical_accuracy: 0.9799\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0986 - categorical_accuracy: 0.9697\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0783 - categorical_accuracy: 0.9813\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0902 - categorical_accuracy: 0.9768\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0771 - categorical_accuracy: 0.9809\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0502 - categorical_accuracy: 0.9847\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0486 - categorical_accuracy: 0.9864\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0388 - categorical_accuracy: 0.9888\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0355 - categorical_accuracy: 0.9894\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0337 - categorical_accuracy: 0.9905\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0239 - categorical_accuracy: 0.9911\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0179 - categorical_accuracy: 0.9932\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0237 - categorical_accuracy: 0.9928\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0160 - categorical_accuracy: 0.9939\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0127 - categorical_accuracy: 0.9959\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0105 - categorical_accuracy: 0.9966 0s - loss: 0.0076 - categori\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0165 - categorical_accuracy: 0.9969\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0073 - categorical_accuracy: 0.9980\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0094 - categorical_accuracy: 0.9973ETA: 0s - loss: 2.7057e-04 - catego\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0096 - categorical_accuracy: 0.9973\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0100 - categorical_accuracy: 0.9973\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0204 - categorical_accuracy: 0.9942\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0148 - categorical_accuracy: 0.9949\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0041 - categorical_accuracy: 0.9986A: 0s - loss: 0.0046 - categorica\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0068 - categorical_accuracy: 0.9976\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0079 - categorical_accuracy: 0.9973 0s - loss: 0.0031 - categori\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0138 - categorical_accuracy: 0.9969\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0148 - categorical_accuracy: 0.9963\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0137 - categorical_accuracy: 0.9963\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0301 - categorical_accuracy: 0.9932\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0395 - categorical_accuracy: 0.9911 0s - loss: 0.0186 - catego\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0666 - categorical_accuracy: 0.9857\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0736 - categorical_accuracy: 0.9820 0s - loss: 0.0907 - categorica\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0501 - categorical_accuracy: 0.9860\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0819 - categorical_accuracy: 0.9785\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0816 - categorical_accuracy: 0.9792 0s - loss: 0.0716 - categorica\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0838 - categorical_accuracy: 0.9751\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1199 - categorical_accuracy: 0.9745\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1015 - categorical_accuracy: 0.9792\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0663 - categorical_accuracy: 0.9843\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0592 - categorical_accuracy: 0.9850 0s - loss: 0.0751 - categorical_accura - ETA: 0s - loss: 0.0688 - categorical_accuracy\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0679 - categorical_accuracy: 0.9850\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0583 - categorical_accuracy: 0.9867\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0736 - categorical_accuracy: 0.9806\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0673 - categorical_accuracy: 0.9843 0s - loss: 0.0555 - categorical_accuracy: 0. - ETA: 0s - loss: 0.0561 - categorica\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0641 - categorical_accuracy: 0.9840\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0344 - categorical_accuracy: 0.9908 0s - loss: 0.0114 - catego\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0246 - categorical_accuracy: 0.9915ETA: 0s - loss: 0.0123 - categori\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0320 - categorical_accuracy: 0.9918\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0421 - categorical_accuracy: 0.9918 0s - loss: 0.0316 - categori\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0459 - categorical_accuracy: 0.9898\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0303 - categorical_accuracy: 0.9928\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0167 - categorical_accuracy: 0.9952\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0140 - categorical_accuracy: 0.9949\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0162 - categorical_accuracy: 0.9952\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0248 - categorical_accuracy: 0.9956A: 0s - loss: 0.0038 - categorica\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0092 - categorical_accuracy: 0.9963\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0061 - categorical_accuracy: 0.9983\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0090 - categorical_accuracy: 0.9963 0s - loss: 0.0078 - categorica\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0167 - categorical_accuracy: 0.9952\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0133 - categorical_accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25e4b993240>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apprentissage\n",
    "nb_epochs = 200 # Param√©trable -> plus cette valeure augmente, plus le mod√®le va apprendre par coeur\n",
    "batch_size = 128 # Param√©trable\n",
    "\n",
    "# Attention, on sauvegarde le mod√®le √† chaque am√©lioration !\n",
    "filepath = os.path.join(subfolder_path, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(network_input, network_output, epochs=nb_epochs, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On liste les models, et le n¬∞ de l'epoch\n",
    "models_list = [(f, int(f.split('-')[2])) for f in os.listdir(subfolder_path) if f.startswith('weights-improvement')]\n",
    "# On sort par epoch\n",
    "models_list = sorted(models_list, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionnel : on va garder les X meilleurs mod√®les pour faire de la place\n",
    "nb_to_keep = 5\n",
    "if len(models_list) > nb_to_keep:\n",
    "    for f in models_list[:-nb_to_keep]:\n",
    "        file_path = os.path.join(subfolder_path, f[0])\n",
    "        os.remove(file_path)\n",
    "models_list = models_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On recharge le meilleur mod√®le\n",
    "# ou le mod√®le de votre choix : les r√©sultats peuvent √™tre plus coh√©rents sur des mod√®les m√™me moins bons\n",
    "model.load_weights(os.path.join(subfolder_path, models_list[-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sauvegarde le mod√®le en entier\n",
    "# Pourquoi ? Car si on change la structure de notre mod√®le, on ne peut pas recharger les poids\n",
    "model.save(os.path.join(subfolder_path, 'model.hdf5'))\n",
    "# Pour reload : model = load_model(path_to_hdf5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pr√©diction\n",
    "\n",
    "<br>\n",
    "\n",
    "- Enfin, on va vouloir utiliser notre mod√®le pour cr√©er un nouveau son !  \n",
    "- Id√©e :  \n",
    "  - Fournir une s√©quence en entr√©e (al√©atoire, une seule note, ou encore une s√©quence choisie manuellement, ...)  \n",
    "  - Pr√©dire la prochaine note  \n",
    "  - Recr√©er une s√©quence avec la nouvelle note (moins la premi√®re note de la s√©quence pr√©c√©dente)  \n",
    "  - Continuer jusqu'√† avoir un certain nombre de notes  \n",
    "- La fonction de g√©n√©ration inclut une s√©lection \"al√©atoire\" selon la distribution des pr√©dictions obtenues par le mod√®le, pour apporter un peu de vari√©t√©.\n",
    "<br>   \n",
    "<br>   \n",
    "\n",
    "On d√©finit quelques fonctions pour clarifier le notebook :\n",
    "\n",
    "- **generate_new_pattern** : Fonction pour g√©n√©rer un nouveau son\n",
    "- **new_song_as_midi_messages** : Function pour transformer une suite de notes en messages MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6209923282278455000() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6209923282278455000()\" id=\"code_toggle_6209923282278455000\">Toggle show/hide --- fonction generate_new_pattern</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_new_pattern(model, notes_to_tokens: dict, nb_notes: int = 150, entry_note: str = None, entry_pattern: list = None,\n",
    "                         use_random_distribution: bool = False, temperature: float = 1.0):\n",
    "    '''Fonction pour g√©n√©rer un nouveau son\n",
    "    On prend notre mod√®le entrain√©, et on g√©n√®re un son √† partir d'un pattern en entr√©e.\n",
    "    Soit : \n",
    "        - Un pattern al√©atoire. On g√©n√®re une s√©quence al√©atoire, mais en respectant la r√©partition des notes.\n",
    "        - Une note seule en entr√©e\n",
    "        - Un pattern 'custom' en entr√©e\n",
    "\n",
    "    Args:\n",
    "        model: mod√®le √† utiliser\n",
    "        notes_to_tokens (dict): tokenizer en entr√©e du mod√®le\n",
    "        nb_notes (int): nombre de notes √† g√©n√©rer\n",
    "        entry_note (str): note seule en entr√©e\n",
    "            Si pr√©cis√©e, on va commencer avec un pattern avec des fausses notes, puis la note souhait√©e\n",
    "        entry_pattern (list): pattern √† utiliser en entr√©e\n",
    "            Si inf√©rieur √† la taille de s√©quence du mod√®le, on ajoute des fausses notes au d√©but\n",
    "            Si sup√©rieur, on garde que les notes de fin\n",
    "            \n",
    "            Si entry_note & entry_pattern de pr√©cis√©, on retourne une erreur.\n",
    "            Si aucun des deux, on va cr√©er un pattern al√©atoire\n",
    "        use_random_distribution (bool): si la prochaine note est choisie al√©atoirement selon la distribution des pr√©dictions\n",
    "            ou si on prend syst√©matiquement la plus probable\n",
    "        temperature (float): param√®tre qui influence sur le choix \"al√©atoire\" du prochain caract√®re\n",
    "            < 1.0 -> on va favoriser le caract√®re le plus probable\n",
    "            > 1.0 -> on va donner plus de \"chances\" aux autres caract√®res\n",
    "    Returns:\n",
    "        prediction_output (list): notre chanson !\n",
    "    '''\n",
    "    # Manage errors\n",
    "    if (entry_note is not None) and (entry_pattern is not None):\n",
    "        raise AttributeError(\"On ne peut pas avoir entry_note & entry_pattern de set en m√™me temps\")\n",
    "\n",
    "    ###\n",
    "    ### Create entry pattern\n",
    "    ###\n",
    "\n",
    "    sequence_length = model.input.shape[-1]\n",
    "    token_oov = len(notes_to_tokens) # Out of Vocabulary token (i.e. 'fausse' note)\n",
    "    tokens_to_notes = {v: k for k, v in notes_to_tokens.items()}\n",
    "    \n",
    "    # Entry note\n",
    "    if entry_note is not None:\n",
    "        print(f\"Cr√©ation d'une s√©quence avec une seule note : {entry_note}\")\n",
    "        tokenized_pattern = [token_oov for i in range(sequence_length-1)]\n",
    "        tokenized_pattern.append(notes_to_tokens[entry_note])\n",
    "        # Prepare model format\n",
    "        tokenized_pattern = np.reshape(tokenized_pattern, (sequence_length, 1))\n",
    "        # Set initial output sequence\n",
    "        prediction_output = [entry_note]\n",
    "        \n",
    "    # Entry pattern\n",
    "    elif entry_pattern is not None:\n",
    "        print(\"Cr√©ation d'une s√©quence avec un pattern en entr√©e\")\n",
    "        # Gestion pattern trop grand\n",
    "        if len(entry_pattern) >= sequence_length:\n",
    "            entry_pattern = entry_pattern[-sequence_length:]\n",
    "            tokenized_pattern = [notes_to_tokens[note] for note in entry_pattern]\n",
    "        # Gestion pattern trop petit\n",
    "        elif len(entry_pattern) < sequence_length:\n",
    "            tokenized_pattern = [token_oov for i in range(sequence_length-len(entry_pattern))]\n",
    "            for note in entry_pattern:\n",
    "                tokenized_pattern.append(notes_to_tokens[note])\n",
    "        # Prepare model format\n",
    "        tokenized_pattern = np.reshape(tokenized_pattern, (sequence_length, 1))\n",
    "        # Set initial output sequence\n",
    "        prediction_output = entry_pattern\n",
    "\n",
    "    # Random !\n",
    "    else:\n",
    "        print(\"Cr√©ation d'une s√©quence avec un pattern al√©atoire en entr√©e\")\n",
    "        pattern = [random.choice(list(notes_to_tokens.keys())) for i in range(sequence_length)]\n",
    "        tokenized_pattern = [notes_to_tokens[note] for note in pattern]\n",
    "        # Prepare model format\n",
    "        tokenized_pattern = np.reshape(tokenized_pattern, (sequence_length, 1))\n",
    "        # Set initial output sequence\n",
    "        prediction_output = []\n",
    "\n",
    "    ###\n",
    "    ### Generate notes\n",
    "    ###\n",
    "\n",
    "    # Si on veut une r√©partition al√©atoire selon la distribution, c'est plus simple de travailler sur les logits\n",
    "    # En effet, permet d'utiliser le param√®tre \"temperature\" pour contr√¥ller l'importance de l'al√©atoire\n",
    "    if use_random_distribution:\n",
    "        model.layers[-1].activation = None\n",
    "    else:\n",
    "        model.layers[-1].activation = Softmax()\n",
    "    \n",
    "    for i, note_index in enumerate(range(nb_notes)):\n",
    "        # Display\n",
    "        if i % 10 == 0 or i == nb_notes - 1:\n",
    "            sys.stdout.write(f\"\\r{i+1}/{nb_notes}\")\n",
    "        \n",
    "        # Predict\n",
    "        prediction_input = np.reshape(tokenized_pattern, (1, len(tokenized_pattern), 1))\n",
    "        prediction = model(prediction_input, training=False)\n",
    "\n",
    "        if use_random_distribution:\n",
    "            # On r√©cup√®re une note \"al√©atoire\" selon la distribution obtenue\n",
    "            prediction = prediction / temperature\n",
    "            predicted_ix = tf.random.categorical(prediction, num_samples=1)\n",
    "            index = predicted_ix.numpy()[0][0]\n",
    "        else:\n",
    "            # On r√©cup√®re la classe (note) avec la plus haute probabilit√©, et on l'ajoute √† notre chanson !\n",
    "            index = np.argmax(prediction)\n",
    "\n",
    "        result = tokens_to_notes[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        # On met en place la sequence suivante\n",
    "        tokenized_pattern = np.append(tokenized_pattern[1:], [index])\n",
    "        tokenized_pattern = np.reshape(tokenized_pattern, (sequence_length, 1))\n",
    "    \n",
    "    # On remet l'activation √† softmax\n",
    "    model.layers[-1].activation = Softmax()\n",
    "    \n",
    "    # Return\n",
    "    return prediction_output\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction generate_new_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2798046188274038521() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2798046188274038521()\" id=\"code_toggle_2798046188274038521\">Toggle show/hide --- fonction new_song_as_midi_messages</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def new_song_as_midi_messages(new_song: list, interval_time: float):\n",
    "    '''Function pour transformer une suite de notes en messages MIDI\n",
    "    \n",
    "    Args:\n",
    "        new_song (list): list de notes (classes)\n",
    "        interval_time (float): interval de temps entre deux notes\n",
    "    Returns:\n",
    "        list: list of midi messages\n",
    "    '''\n",
    "    # On va recr√©er les messages MIDI\n",
    "    # Pour chaque note, on va ajouter √† la variable \"time\" autant de fois \"interval_time\"\n",
    "    # qu'il y a eu de blancs depuis la derni√®re note.\n",
    "    midi_messages = []\n",
    "    nb_blanc = 0 # On compte le nombre de blancs\n",
    "    for new_note in new_song:\n",
    "        # Si note blanc, on rajoute au compteur de blancs √† consid√©rer\n",
    "        if new_note.startswith('blanc'):\n",
    "            if new_note == 'blanc':\n",
    "                nb_blanc += 1\n",
    "            else:\n",
    "                nb_blanc += int(new_note.split('_')[-1]) # e.g. 'blanc_6' -> 6 blancs\n",
    "        # Sinon, on ajoute la note √† la liste de messages\n",
    "        else:\n",
    "            note = int(new_note.split('_')[0])\n",
    "            velocity = int(new_note.split('_')[1])\n",
    "            wait_time = (1 + nb_blanc) * interval_time\n",
    "            channel = 9 # Sp√©cifique √† notre projet, pourrait √™tre param√©tr√©\n",
    "            msg = mido.Message('note_on', channel=channel, note=note, velocity=velocity, time=wait_time)\n",
    "            midi_messages.append(msg)\n",
    "            # Reset nb_blanc\n",
    "            nb_blanc = 0\n",
    "\n",
    "    # La premi√®re note commence avec un temps √† 0\n",
    "    midi_messages[0].time = 0\n",
    "    \n",
    "    # Return\n",
    "    return midi_messages\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction new_song_as_midi_messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cr√©ation d'une s√©quence avec un pattern al√©atoire en entr√©e\n",
      "200/200"
     ]
    }
   ],
   "source": [
    "# G√©n√©ration d'une nouvelle chanson - sans s√©lection al√©atoire selon la distribution des pr√©dictions\n",
    "# new_song = generate_new_pattern(model, notes_to_tokens, nb_notes=200, entry_note='36_101') # Une seule note\n",
    "# new_song = generate_new_pattern(model, notes_to_tokens, nb_notes=200) # Al√©atoire\n",
    "\n",
    "# On peut aussi ajouter un peu d'al√©atoire - avec s√©lection al√©atoire selon la distribution des pr√©dictions\n",
    "# Le choix de la valeur temperature va g√©n√©ralement d√©pendre de notre mod√®le\n",
    "# Plus le mod√®le est performant, plus on va souhait√© augmenter cette valeur pour avoir un peu d'al√©atoire dans les g√©n√©rations\n",
    "# Sinon, on va avoir tendance √† baisser cette valeur pour avoir plus de coh√©rence dans les beats g√©n√©r√©s\n",
    "new_song = generate_new_pattern(model, notes_to_tokens, nb_notes=200, use_random_distribution = True, temperature = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduction au format MIDI (messages)\n",
    "new_song_midi_messages = new_song_as_midi_messages(new_song, interval_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut jouer notre nouveau song !\n",
    "play_midi_messages(new_song_midi_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "save_midi_messages(new_song_midi_messages, os.path.join(subfolder_path, datetime.now().strftime(f\"new_song_%Y_%m_%d-%H_%M_%S.mid\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez ensuite convertir votre fichier .midi en .wav avec un converter en ligne, par exemple : https://www.zamzar.com/fr/converters/audio/midi-to-wav/  \n",
    "Attention, le r√©sultat audio peut √™tre diff√©rent en fonction du synthesizer utilis√©.\n",
    "\n",
    "Vous pouvez aussi le faire en local avec VLC : https://ourcodeworld.com/articles/read/1400/how-to-convert-a-midi-file-to-mp3-using-headless-vlc-player-with-the-cli-in-windows-10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©f√©rences :\n",
    "\n",
    "- [How to Generate Music using a LSTM Neural Network in Keras](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5), *Sigur√∞ur Sk√∫li*, 2017  \n",
    "- [WaveNet: A Generative Model for Raw Audio](https://arxiv.org/pdf/1609.03499.pdf), *Aaron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu*, 2016\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_devfest",
   "language": "python",
   "name": "venv_devfest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
