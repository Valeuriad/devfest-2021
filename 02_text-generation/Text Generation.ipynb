{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation - DevFest Nantes 2021 - IArt\n",
    "\n",
    " \n",
    "<br>  \n",
    "Brique n¬∞2 de la conf√©rence **IArt ou comment apprendre √† une machine √† tagger et √† composer**\n",
    " \n",
    "<br>  \n",
    "\n",
    "<img src=\"images/image1.jpg\" alt=\"Text Generation\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectifs\n",
    " \n",
    "<br>  \n",
    "- Introduction √† la g√©n√©ration de texte\n",
    "<br>  \n",
    "<br>  \n",
    "- G√©n√©rer les paroles de notre tube üìúüìùüìã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapes\n",
    "\n",
    "<br>  \n",
    "1. Chargement des donn√©es\n",
    "<br>  \n",
    "    - Chargement du dataset dans une seule \"string\" et suppression de certains caract√®res en trop.\n",
    "    - On va ensuite tokeniser cette chaine de caract√®re (i.e. transformation en s√©quence d'identifiants).  \n",
    "<br>  \n",
    "2. Pr√©paration du dataset pour la mod√©lisation\n",
    "<br>  \n",
    "    - On va s√©parer notre jeu de donn√©es en s√©quences de X caract√®res\n",
    "    - Pour chaque s√©quence, on s√©pare en input / output:\n",
    "        - Input : La s√©quence moins le dernier caract√®re\n",
    "        - Output : La prochaine s√©quence √† pr√©dire, i.e. la s√©quence moins le premier caract√®re\n",
    "    - On termine par cr√©er un g√©n√©rateur de batchs, qui sera utilis√© pour l'apprentissage de notre mod√®le  \n",
    "<br>  \n",
    "3. Mod√©lisation\n",
    "<br>  \n",
    "    - On va d√©finir un mod√®le de type RNN adapt√© √† notre probl√®me.  \n",
    "<br>  \n",
    "4. Entrainement\n",
    "<br>  \n",
    "    - On entraine le mod√®le sur l'int√©gralit√© de nos donn√©es.\n",
    "        - Pas oblig√© d'avoir un jeu de validation, on veut volontairement overfitter le mod√®le pour apprendre au mieux le \"genre\" des paroles en entr√©e.  \n",
    "<br>  \n",
    "5. Pr√©dictions\n",
    "<br>  \n",
    "    - On termine par g√©n√©rer de nouvelles paroles √† partir d'un texte en entr√©e.\n",
    "        - La fonction de g√©n√©ration inclut une s√©lection \"al√©atoire\" selon la distribution des pr√©dictions obtenues par le mod√®le, pour apporter un peu de vari√©t√©.  \n",
    "<br>  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donn√©es\n",
    "\n",
    "<br>  \n",
    "On va utiliser un ensemble de paroles de musique de Hip-Hop. Cet ensemble provient d'un scrapping de Metro Lyrics, mais il est devenu un peu compliqu√© de trouver sur internet. On a pu le r√©cup√©rer ici : https://github.com/ludovicaschaerf/TMCI_Project/blob/master/data/380000-lyrics-from-metrolyrics.zip\n",
    "\n",
    "Ce jeu de donn√©es √† √©t√© pr√©process√© avant d'√™tre pouss√© sur ce Git. On a filtr√© les musiques de type \"Hip-Hop\" et r√©alis√© quelques pr√©traitements sur les paroles. Ces derniers ne sont pas parfaits, mais √ßa fait largement l'affaire pour notre projet.  \n",
    "\n",
    "Le code utilis√© est mis √† disposition √† la fin de ce notebook pour information.  \n",
    "\n",
    "\n",
    "(Certaines chansons ne sont pas forc√©ment en anglais, mais il y en a tr√®s peu, donc on ignore le probl√®me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divers\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, Javascript, clear_output\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Center figures\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions utilitaires\n",
    "\n",
    "<br>  \n",
    "On commence par d√©finir certaines fonctions utilitaires :\n",
    "\n",
    "- **hide_toggle** : permet de \"masquer\" certaines cellules de ce notebook, ce qui permet d'apporter un peu plus de clart√© ;)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_4366748953531476569() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_4366748953531476569()\" id=\"code_toggle_4366748953531476569\">Toggle show/hide --- fonction hide_toggle</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hide_toggle(for_next=False, text_display='Toggle show/hide'):\n",
    "    '''Function to hide a notebook cell'''\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = f\"\"\"\n",
    "        <script>\n",
    "            function {js_f_name}() {{\n",
    "                {target_cell}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{js_f_name}()\" id=\"{js_f_name}\">{text_display}</a>\n",
    "    \"\"\"\n",
    "    \n",
    "    js = f'''\n",
    "            var output_area = this;\n",
    "            var cell_element = output_area.element.parents('.cell');\n",
    "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
    "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
    "            $(current_cell.element[0]).find('div.input').toggle();\n",
    "            Jupyter.notebook.select(cell_idx +  1);\n",
    "            Jupyter.notebook.focus_cell();\n",
    "         '''\n",
    "\n",
    "    display(HTML(html))\n",
    "    display(Javascript(js))\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction hide_toggle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chargement des donn√©es\n",
    "\n",
    "<br>\n",
    "\n",
    "- Chargement du dataset dans une seule \"string\" et suppression de certains caract√®res en trop.\n",
    "- On va ensuite tokeniser cette chaine de caract√®re (i.e. transformation en s√©quence d'identifiants).\n",
    "<br>   \n",
    "<br>   \n",
    "\n",
    "On d√©finit quelques fonctions pour clarifier le notebook :\n",
    "\n",
    "- **text_from_ids** : Fonction pour retransformer une s√©quence d'identifiants en texte  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_13473338110408210803() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_13473338110408210803()\" id=\"code_toggle_13473338110408210803\">Toggle show/hide --- fonction text_from_ids</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def text_from_ids(seq: list, ids_from_chars):\n",
    "    '''Fonction pour retransformer une s√©quence d'identifiants en texte\n",
    "    \n",
    "    Args:\n",
    "        seq (list): liste d'identifiants √† transformer en texte\n",
    "        ids_from_chars: tokenizer utilis√© pour cr√©er les identifiants\n",
    "    Returns:\n",
    "        str: texte en sortie\n",
    "    '''\n",
    "    # Utilitaire TF pour transformer les IDs en texte\n",
    "    chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "    \n",
    "    # Apply\n",
    "    text = tf.strings.reduce_join(chars_from_ids(seq), axis=-1).numpy().decode('utf-8')\n",
    "\n",
    "    # Return\n",
    "    return text\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction text_from_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de donn√©es et concat√©nation dans une seule string\n",
    "full_lyrics = \" . \".join(pd.read_csv(\"lyrics/lyrics_hip_hop.csv\", sep=';', encoding='utf-8')[\"lyrics\"].values)\n",
    "# On pourrait tout mettre en lower pour diminuer le nombre de \"classes\" possible (i.e. de caract√®re possible)\n",
    "\n",
    "\n",
    "# Attention, l'entrainement d'un mod√®le sur l'int√©gralit√© des donn√©es avec une GPU GTX 1070 peut prendre plus de deux heures\n",
    "# Vous pouvez donc r√©duire la taille du dataset si vous le souhaitez\n",
    "# e.g. full_lyrics = full_lyrics[:1000000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime certains caract√®res en trop (on aurait pu le faire dans le preprocessing)\n",
    "full_lyrics = re.sub(r\"[&#¬£$‚Ç¨%<>=@\\^`\\{\\}|~\\t\\x18\\x7f]\", '', full_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notre jeu de donn√©es est compos√© de 59100439 caract√®res.\n",
      "Il y a 67 caract√®res uniques.\n"
     ]
    }
   ],
   "source": [
    "# Analyse de notre vocabulaire -> 1 caract√®re = 1 classe de notre mod√®le\n",
    "vocab = sorted(set(full_lyrics))\n",
    "print(f\"Notre jeu de donn√©es est compos√© de {len(full_lyrics)} caract√®res.\")\n",
    "print(f\"Il y a {len(vocab)} caract√®res uniques.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "ids_from_chars = preprocessing.StringLookup(vocabulary=vocab, mask_token=None)\n",
    "# Application sur nos donn√©es\n",
    "lyrics_ids = ids_from_chars(tf.strings.unicode_split(full_lyrics, 'UTF-8'))\n",
    "# Cr√©ation d'un Dataset au format tensorflow\n",
    "lyrics_ids_dataset = tf.data.Dataset.from_tensor_slices(lyrics_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pr√©paration du dataset pour la mod√©lisation\n",
    "\n",
    "<br>\n",
    "\n",
    "- On va s√©parer notre jeu de donn√©es en s√©quences de X caract√®res\n",
    "- Pour chaque s√©quence, on s√©pare en input / output:\n",
    "    - Input : La s√©quence moins le dernier caract√®re\n",
    "    - Output : La prochaine s√©quence √† pr√©dire, i.e. la s√©quence moins le premier caract√®re\n",
    "- On termine par cr√©er un g√©n√©rateur de batchs, qui sera utilis√© pour l'apprentissage de notre mod√®le\n",
    "<br>   \n",
    "<br>   \n",
    "\n",
    "On d√©finit quelques fonctions pour clarifier le notebook :\n",
    "\n",
    "- **split_input_target** : Fonction pour s√©parer une s√©quence (suite de caract√®res) en input/output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_13792729394141310274() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_13792729394141310274()\" id=\"code_toggle_13792729394141310274\">Toggle show/hide --- fonction split_input_target</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_input_target(sequence):\n",
    "    '''Fonction pour s√©parer une s√©quence (suite de caract√®res) en input/output\n",
    "    \n",
    "    Args:\n",
    "        sequence: suite de caract√®res\n",
    "    Returns:\n",
    "        ? : input\n",
    "        ? : output\n",
    "    '''\n",
    "    input_text = sequence[:-1]  # Input : toute la s√©quence sauf le dernier caract√®re\n",
    "    target_text = sequence[1:]  # Output : toute la s√©quence sauf le premier caract√®re\n",
    "    # Returns\n",
    "    return input_text, target_text\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction split_input_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres\n",
    "sequence_length = 100  # Longueur des s√©quences\n",
    "batch_size = 1024  # Taille des batchs pour l'apprentissage, utile ici pour le generator\n",
    "buffer_size = 10000  # Utilis√© pour m√©langer le dataset sans tout charger en m√©moire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des s√©quences (length + 1 pour ajouter le prochain caract√®re)\n",
    "sequences = lyrics_ids_dataset.batch(sequence_length + 1, drop_remainder=True)\n",
    "# Gestion des inputs/outputs\n",
    "model_dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : . Timbo When you hit me on my phone betta know what cha want when you call me you already know on th\n",
      "Target:  Timbo When you hit me on my phone betta know what cha want when you call me you already know on the\n"
     ]
    }
   ],
   "source": [
    "# Affichage - exemple d'un couple input/output\n",
    "for input_example, target_example in model_dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example, ids_from_chars))\n",
    "    print(\"Target:\", text_from_ids(target_example, ids_from_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset (generator) final √† utiliser en entr√©e du mod√®le\n",
    "model_dataset = model_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mod√©lisation\n",
    "<br>\n",
    "\n",
    "- On va d√©finir un mod√®le de type RNN adapt√© √† notre probl√®me\n",
    "<br>   \n",
    "<br>   \n",
    "\n",
    "On d√©finit quelques fonctions & classes pour clarifier le notebook :\n",
    "\n",
    "- **ModelGenerationText** : Mod√®le principal pour la g√©n√©ration de texte\n",
    "- **get_model_loss** : Fonction pour d√©finir une loss √† notre mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_16327090966094336589() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_16327090966094336589()\" id=\"code_toggle_16327090966094336589\">Toggle show/hide --- classe ModelGenerationText</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ModelGenerationText(tf.keras.Model):\n",
    "    '''Mod√®le principal pour la g√©n√©ration de texte'''\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, rnn_units: int):\n",
    "        '''Initialisation de la classe\n",
    "        \n",
    "        Args:\n",
    "            vocab_size (int): taille du vocabulaire (i.e. classes possibles)\n",
    "            embedding_size (int): Dimension de l'embedding\n",
    "            rnn_units (int): Nombre d'unit√©s RNN\n",
    "        '''\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, trainable=True)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training: bool = False):\n",
    "        '''Appel au model\n",
    "        \n",
    "        Args:\n",
    "            inputs: donn√©es en entr√©e\n",
    "            states: √©tats RNN √† utiliser si pr√©cis√©\n",
    "            return_state: si les √©tats RNN doivent √™tre retourn√©s\n",
    "            training (bool): si on est en phase d'entrainement\n",
    "        Returns:\n",
    "            ?: outputs du mod√®le\n",
    "            ?: (optionnel) √©tats des RNNs\n",
    "        '''\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        # Si pas de states de pr√©cis√©, on initialise les RNNs\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        # R√©cup√©ration de la sortie des RNNs ainsi que des states\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        # Suite du mod√®le\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        # Return en fonction de l'argument return_state\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- classe ModelGenerationText')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_646011781585871339() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_646011781585871339()\" id=\"code_toggle_646011781585871339\">Toggle show/hide --- fonction get_model_loss</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_model_loss():\n",
    "    '''Fonction pour d√©finir une loss √† notre mod√®le'''\n",
    "    # From logits car on n'a pas de couche de softmax en sortie, on r√©cup√®re directement les logits\n",
    "    # Sparse car on a beaucoup de cat√©gories\n",
    "    return tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction get_model_loss')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim = 100  # Dimension de l'embedding\n",
    "rnn_units = 1024  # Nombre d'unit√©s RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init. mod√®le\n",
    "model = ModelGenerationText(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/image2.png\" alt=\"Text Generation\" width=\"600\" />\n",
    "\n",
    "*Image from https://www.tensorflow.org/text/tutorials/text_generation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©ration de la loss & compile de notre mod√®le\n",
    "lr = 0.001  # Param√©trable\n",
    "loss = get_model_loss()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_generation_text\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  6800      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3459072   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  69700     \n",
      "=================================================================\n",
      "Total params: 3,535,572\n",
      "Trainable params: 3,535,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# On passe le mod√®le sur 1 s√©quence pour lui donner les informations de \"shape\" et pouvoir afficher sa description\n",
    "for input_example_batch, target_example_batch in model_dataset.take(1):\n",
    "    model(input_example_batch)\n",
    "# Affichage\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrainement\n",
    "<br>\n",
    "\n",
    "- On entraine le mod√®le sur l'int√©gralit√© de nos donn√©es.\n",
    "    - Pas oblig√© d'avoir un jeu de validation, on veut volontairement overfitter le mod√®le pour apprendre au mieux le \"genre\" des paroles en entr√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'ensemble des r√©sultats seront sauvegard√©es dans le r√©pertoire C:\\Users\\Alexandre\\Dev\\Valeuriad\\devfest-2021\\02_text-generation\\experimentation_2021_10_17-15_46_58\n"
     ]
    }
   ],
   "source": [
    "# On va cr√©er un dossier o√π sauvegarder nos r√©sultats\n",
    "subfolder_name = datetime.now().strftime(f\"experimentation_%Y_%m_%d-%H_%M_%S\")\n",
    "os.makedirs(subfolder_name)\n",
    "subfolder_path = os.path.abspath(subfolder_name)\n",
    "print(f\"L'ensemble des r√©sultats seront sauvegard√©es dans le r√©pertoire {subfolder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion des sauvegardes du meilleur mod√®le\n",
    "# Nom du fichier o√π sauvegarder le meilleur mod√®le\n",
    "checkpoint_filepath = os.path.join(subfolder_path, \"best_weights\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 [==============================] - 50s 525ms/step - loss: 3.1832\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 2.3791\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 51s 527ms/step - loss: 2.1670\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 1.9914\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 53s 553ms/step - loss: 1.8587\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 51s 529ms/step - loss: 1.7583\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 1.6793\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 1.6137\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 1.5631\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 51s 527ms/step - loss: 1.5231\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 51s 529ms/step - loss: 1.4892\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 1.4608\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 1.4355\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 51s 528ms/step - loss: 1.4133\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 51s 529ms/step - loss: 1.3934\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 51s 529ms/step - loss: 1.3752\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 51s 527ms/step - loss: 1.3579\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 51s 526ms/step - loss: 1.3422\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 50s 524ms/step - loss: 1.3274\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 50s 524ms/step - loss: 1.3126\n"
     ]
    }
   ],
   "source": [
    "# Entrainement\n",
    "nb_epochs = 20\n",
    "history = model.fit(model_dataset, epochs=nb_epochs, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x12a7c8d83c8>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On recharge le meilleur mod√®le\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pr√©dictions\n",
    "<br>\n",
    "\n",
    "- On termine par g√©n√©rer de nouvelles paroles √† partir d'un texte en entr√©e.\n",
    "    - La fonction de g√©n√©ration inclut une s√©lection \"al√©atoire\" selon la distribution des pr√©dictions obtenues par le mod√®le, pour apporter un peu de vari√©t√©.  \n",
    "<br>   \n",
    "<br>   \n",
    "\n",
    "On d√©finit quelques fonctions & classes pour clarifier le notebook :\n",
    "\n",
    "- **TextPredictor** : Classe qui permet de g√©n√©rer un nouveau caract√®re √† la suite d'une s√©quence √† partir d'un mod√®le entrain√©\n",
    "- **generate_text** : Fonction pour g√©n√©rer du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_13570466653801849297() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_13570466653801849297()\" id=\"code_toggle_13570466653801849297\">Toggle show/hide --- classe TextPredictor</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TextPredictor(tf.keras.Model):\n",
    "    '''Classe qui permet de g√©n√©rer un nouveau caract√®re √† la suite d'une s√©quence √† partir d'un mod√®le entrain√©'''\n",
    "    \n",
    "    def __init__(self, model, ids_from_chars, use_random_distribution: bool = True, temperature: float = 1.0):\n",
    "        '''Initialisation de la classe\n",
    "        \n",
    "        Args:\n",
    "            model: mod√®le √† utiliser pour les pr√©dictions\n",
    "            ids_from_chars: tokenizer   \n",
    "            use_random_distribution (bool): si le prochain caract√®re est choisie al√©atoirement selon la distribution des pr√©dictions\n",
    "                ou si on prend syst√©matiquement le plus probable (attention, grande chance de r√©p√©tition dans le texte de sortie)\n",
    "            temperature (float): param√®tre qui influence sur le choix \"al√©atoire\" du prochain caract√®re\n",
    "                < 1.0 -> on va favoriser le caract√®re le plus probable\n",
    "                > 1.0 -> on va donner plus de \"chances\" aux autres caract√®res\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.use_random_distribution = use_random_distribution\n",
    "        self.temperature = temperature\n",
    "        self.chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "        # On d√©finit un mask pour √©viter les predictions \"[UNK]\" (classe 'unknown' du tokenizer)\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values=[-float('inf')] * len(skip_ids), # -inf √† chaque mauvais index\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        '''Fonction pour g√©n√©rer un nouveau caract√®re\n",
    "        \n",
    "        Args:\n",
    "            inputs: s√©quences textuelles en entr√©e\n",
    "            states: √©tats des RNNs (d√©fault None)\n",
    "        '''\n",
    "        # On commence par transformer les phrases en IDs\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "        \n",
    "\n",
    "        # On fait tourner le mod√®le sur nos inputs\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "        \n",
    "        # On r√©cup√®re uniquement la pr√©diction sur le dernier caract√®re\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        if self.use_random_distribution:\n",
    "            predicted_logits = predicted_logits / self.temperature\n",
    "\n",
    "        # On applique le masque pour enlever le caract√®re [UNK]\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # On r√©cup√®re les IDs √† partir des logits obtenues via les pr√©dictions\n",
    "        if self.use_random_distribution:\n",
    "            # On r√©cup√®re un caract√®re \"al√©atoire\" selon la distribution obtenue\n",
    "            predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "            predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "        else:\n",
    "            # On prend la caract√®re le plus probable\n",
    "            predicted_ids = tf.math.argmax(predicted_logits, axis=-1)\n",
    "\n",
    "        # On retransforme en texte\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # On retourne les caract√®res obtenus et les √©tats RNN\n",
    "        return predicted_chars, states\n",
    "\n",
    "    \n",
    "hide_toggle(text_display='Toggle show/hide --- classe TextPredictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_8874866568599644033() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_8874866568599644033()\" id=\"code_toggle_8874866568599644033\">Toggle show/hide --- fonction generate_text</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var output_area = this;\n",
       "            var cell_element = output_area.element.parents('.cell');\n",
       "            var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
       "            var current_cell = Jupyter.notebook.get_cell(cell_idx);\n",
       "            $(current_cell.element[0]).find('div.input').toggle();\n",
       "            Jupyter.notebook.select(cell_idx +  1);\n",
       "            Jupyter.notebook.focus_cell();\n",
       "         "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_text(predictor, original_text: str, nb_chars: int = 100):\n",
    "    '''Fonction pour g√©n√©rer du texte\n",
    "    \n",
    "    Args:\n",
    "        original_text (str): phrase en entr√©e\n",
    "        nb_chars (int): nombre de caract√®res √† cr√©er\n",
    "    Returns:\n",
    "        str: new song !\n",
    "    '''\n",
    "    start = time.time()\n",
    "\n",
    "    # Init. variables\n",
    "    states = None  # Pas d'√©tat au d√©but\n",
    "    next_char = tf.constant([original_text])\n",
    "    result = [next_char]\n",
    "\n",
    "    # Pr√©diction des nouveaux caract√®res\n",
    "    for n in range(nb_chars):\n",
    "        next_char, states = predictor.generate_one_step(next_char, states=states)\n",
    "        result.append(next_char)\n",
    "\n",
    "    # Resultats finaux\n",
    "    result = tf.strings.join(result)\n",
    "    \n",
    "    # Result as string\n",
    "    result_str = result[0].numpy().decode('utf-8')\n",
    "    \n",
    "    # On recolle les points\n",
    "    result_str = re.sub(r\"(?<=\\w)\\s+\\!\", '!', result_str)\n",
    "    result_str = re.sub(r\"(?<=\\w)\\s+\\?\", '?', result_str)\n",
    "    result_str = re.sub(r\"(?<=\\w)\\s+\\.\", '.', result_str)\n",
    "    \n",
    "    # Affichage temps\n",
    "    end = time.time()\n",
    "    print(f\"Temps de traitement : {end - start}s\")\n",
    "    \n",
    "    return result_str\n",
    "\n",
    "\n",
    "hide_toggle(text_display='Toggle show/hide --- fonction generate_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cr√©√© notre predictor\n",
    "# Le choix de la valeur temperature va g√©n√©ralement d√©pendre de notre mod√®le\n",
    "# Plus le mod√®le est performant, plus on va souhait√© augmenter cette valeur pour avoir un peu d'al√©atoire dans les g√©n√©rations\n",
    "# Sinon, on va avoir tendance √† baisser cette valeur pour avoir plus de coh√©rence dans le texte g√©n√©r√©\n",
    "predictor = TextPredictor(model, ids_from_chars, use_random_distribution=True, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'u'], dtype=object)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generation d'un caract√®re - exemple\n",
    "predictor.generate_one_step(tf.constant(['yo']))[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de traitement : 2.4155220985412598s\n",
      "Devfest is what club is a man but I don't like me I need you I don't see you with the weekend How I promise you broke you don't be blastin' I got the pain I don't care if I can see it in my life I love her a day I got something for this Walk that work it out see my shit bang Now a nigga with a fantass on my back off your back get your head like the barr to the car And the streets want to fuck with the good on the town You better be ready for the niggaz in the pen to the beat They say that you wanna fuck your face I had a lot of thing she love me say I make it a real nigga stay gettin' money I had to tell you when you get a chick shit She can do is come on and get you out here tryna function I know you make my day I got rich I don't wanna be with you I know I'm a soldier I can't do it for my life I got the system you know I'm the best I love to see the life is the way I like I was born in the game I can't stand it I'm a motherfucking game you know I wanna do me feel the streets to be hard or go h\n"
     ]
    }
   ],
   "source": [
    "# On g√©n√®re de nouvelles paroles\n",
    "\n",
    "# DISCLAIMER : les paroles de Hip-Hop peuvent contenir des insultes, obsc√©nit√©s, etc..\n",
    "#              il est donc normal que notre algorithme fasse pareil ...\n",
    "\n",
    "initial_text = \"Devfest is\"  # Texte de base √† utiliser\n",
    "new_song_lyrics = generate_text(predictor, initial_text, nb_chars=1000)\n",
    "# Affichage\n",
    "print(new_song_lyrics)\n",
    "# Sauvegarde\n",
    "save_path = os.path.join(subfolder_path, datetime.now().strftime(f\"lyrics_%Y_%m_%d-%H_%M_%S.txt\"))\n",
    "with open(save_path, 'w') as f:\n",
    "    f.write(new_song_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Misc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour information, le code utilis√© pour faire le pr√©traitement du jeu de donn√©es original est le suivant :\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"lyrics/lyrics_full.csv\", sep=',', encoding='utf-8')  # Fichier non disponbile\n",
    "df = df[~df[\"lyrics\"].isna()]  # On enl√®ve les NaNs\n",
    "text = df[df[\"genre\"]=='Hip-Hop']  # Filtre Hip-Hop\n",
    "text = text[text.lyrics.apply(len) > 200]  # On garde les paroles avec assez de texte\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\?\\s*\\n+\", '? ', x))  # \"? \\n\"  ->   \"? \"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\!\\s*\\n+\", '! ', x))  # \"! \\n\"  ->   \"! \"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\.\\s*\\n+\", '. ', x))  # \". \\n\"  ->   \". \"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\n+\", ' ', x))  # \"\\n\\n\"  ->   \" \"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\!+\\.+\", '!', x))  # \"!.\"  ->   \"!\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\?+\\.+\", '?', x))  # \"?.\"  ->   \"?\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\[[\\w\\d\\s,:\\(\\)\\_\\-\\+\\?\\!\\.\\\"_;/\\\\\\*\\[]*\\]\", ' ', x))  # \"(text)\"  ->   \"\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\([\\w\\d\\s,:\\[\\]\\_\\-\\+\\?\\!\\.\\\"_;/\\\\\\*\\(]*\\)\", ' ', x))  # \"[text]\"  ->   \"\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\!(?=\\w)\", '! ', x))  # \"!text\"  ->   \"! text\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\?(?=\\w)\", '? ', x))  # \"?text\"  ->   \"? text\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\.(?=\\w)\", '. ', x))  # \".text\"  ->   \". text\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"(?<=\\w)\\!\", ' !', x))  # \"text!\"  ->   \"text !\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"(?<=\\w)\\?\", ' ?', x))  # \"text?\"  ->   \"text ?\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"(?<=\\w)\\.\", ' .', x))  # \"text.\"  ->   \"text .\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\.{2,}\", '.', x))  # \"...\"  ->   \".\"  \n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\!{2,}\", '!', x))  # \"!!!\"  ->   \"!\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"\\?{2,}\", '?', x))  # \"???\"  ->   \"?\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"[,:\\[\\]\\(\\)\\\"_\\-\\+_;/\\\\\\*]\", ' ', x))  # \"text, -zea\"  ->   \"text zea\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r'[^\\x00-\\x7f]', '', x))  # Suppression de certains caract√®res non ascii\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"[\\t\\f\\v ]{2,}\", ' ', x))  # \"text  zea\"  ->   \"text zea\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"^(\\s)+\", '', x))  # \" text zea\"  ->   \"text zea\"\n",
    "text[\"lyrics\"] = text[\"lyrics\"].apply(lambda x: re.sub(r\"(\\s)+$\", '', x))  # \"text zea \"  ->   \"text zea\"\n",
    "\n",
    "text[['song', 'artist', 'year', 'lyrics']].reset_index(drop=True).to_csv('lyrics/lyrics_hip_hop.csv', sep=';', encoding='utf-8', index=None)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_devfest",
   "language": "python",
   "name": "venv_devfest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
